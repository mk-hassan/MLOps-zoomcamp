{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff1fa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfe1972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebfcebf",
   "metadata": {},
   "source": [
    "### what is this ?\n",
    "1. xgboost module is imported to use the XGBoost model. see \"XGBoost.ipynb\" where i tried to make a simple regression model\n",
    "2. hyperopt:It's a library that used some **bayesian methods** to try to find the best set of hyperparameters \n",
    "   In terms of hyperopt your model will be just a function that takes some input(combination of hyper parameters) and outputs some values. that function called ***objective function*** \n",
    "   1. fmin: Runs the optmization loop to find the best hyperparameter set. (the hp combination that produces the lowest RMSE)\n",
    "      Used to minimize the objective function(outputs of the model), it depends on the evaluation metric you may need the maximum output.\n",
    "   2. tpe: The algorithm used to pick the next best parameters to try (TPE = Tree-structured Parzen Estimator)\n",
    "   3. hp: library that contains a bunch of different methods to define the search space (the ranges of each hyperparameter that we will use).\n",
    "   4. STATUS_OK: signal that we will send at the end of each run to tell hyperopt that the objective function has run successfully.\n",
    "   5. Trials: will keep track of the information of each run\n",
    "3. scope: used to cast values inside the **search space** to integer, float, etc.\n",
    "\n",
    "summery:\n",
    "trying different hyper-parameter set generated by the **hp** module, each new set is selected using **tpe** algorithm. the **fmin** is used to run the objective function with different parameter set and selects the parameter set that produces the minimum RMSE. So from its name it tries to minimize the RMSE by running the model again and again with different hyper-parameter set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e38126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "    if filename.endswith('.csv'):\n",
    "        df = pd.read_csv(filename)\n",
    "\n",
    "        df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "        df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "    elif filename.endswith('.parquet'):\n",
    "        df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3985ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_dataframe('../data/green_tripdata_2021-01.parquet')\n",
    "df_val = read_dataframe('../data/green_tripdata_2021-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb457d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train), len(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457271cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['PU_DO'] = df_train['PULocationID'] + '_' + df_train['DOLocationID']\n",
    "df_val['PU_DO'] = df_val['PULocationID'] + '_' + df_val['DOLocationID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e165f4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PU_DO'] #'PULocationID', 'DOLocationID'\n",
    "numerical = ['trip_distance']\n",
    "\n",
    "dv = DictVectorizer()\n",
    "\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9d7388",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb94975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\") # path to the tracking server database\n",
    "mlflow.set_experiment(\"nyc-taxi-experiment\") # experiment name, will be              created if not found "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac08784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DMatrix is an optimized data structure used by XGBoost to:\n",
    "# Store your features (X_train, X_val) and labels (y_train, y_val)\n",
    "# Speed up training (it’s faster than using raw NumPy arrays or Pandas)\n",
    "# Handle things like missing values, sparse data, and caching internally\n",
    "\n",
    "train = xgb.DMatrix(X_train, label=y_train)\n",
    "valid = xgb.DMatrix(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c849e750",
   "metadata": {},
   "source": [
    "### Hyper-parameter tunning using XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21254d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Objective function is responsible for training the model \n",
    "with different hyper-parameters and returns RMSE and signal indicates the training has finished successfully\n",
    "\n",
    "The training works as follows: \n",
    "    Start training (up to 1000 rounds)\n",
    "    After each round:\n",
    "        Train a new tree\n",
    "        Evaluate on the validation set\n",
    "        Check if performance improved\n",
    "    If it stops improving for 50 rounds in a row → training stops early\n",
    "    The model automatically keeps the best version it saw during training\n",
    "\"\"\"\n",
    "def objective(params: dict) -> dict:\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"model\", \"xgboost\")\n",
    "        mlflow.log_params(params)\n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=train,\n",
    "            num_boost_round=100, # Try training up to 1000 trees (boosting rounds)\n",
    "            evals=[(valid, 'validation')], # While training, also evaluate the model on this validation set\n",
    "            # If the validation score doesn't improve for 50 rounds, stop training early\n",
    "            # this indicates when to do early stopping to avoid overfitting and wasting time\n",
    "            early_stopping_rounds=20 \n",
    "        )\n",
    "        y_pred = booster.predict(valid)\n",
    "        rmse = root_mean_squared_error(y_val, y_pred)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    return {'loss': rmse, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9378959",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "hp.quniform => from 4 to 100 step 1\n",
    "\"\"\"\n",
    "search_space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "    # this tells the xgboost training algorithm to use RMSE metric in validation after each round\n",
    "    'objective': 'reg:squarederror',\n",
    "    # For predictability\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "the fn parameter is the objective function that is responsible for running the model\n",
    "it's expected to take the params as input\n",
    "and return a dictionary contains two keys \"loss\" and  \"status\"\n",
    "\"\"\"\n",
    "# this call returns a dictionary containing the best parameter set\n",
    "best_result = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    # This tells Hyperopt how to choose the next set of parameters. tpe (Tree-structured Parzen Estimator) is a smart algorithm that learns from past trials to pick better values next time.\n",
    "    algo=tpe.suggest,\n",
    "    # number of runs, each run with different Hypter-parameter set\n",
    "    max_evals=10,\n",
    "    trials=Trials()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbe35a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best hyper parameter combination that makes the lowest loss\n",
    "best_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac280ce",
   "metadata": {},
   "source": [
    "### MLFlow auto logging\n",
    "\n",
    "I will try to train a new model with best hyper-parameters obtained from the previous step using mlflow.autolog\n",
    "\n",
    "Autolog works only for specific frameworks one of them is XGBoost\n",
    "\n",
    "It records the hyper-parameters, metrics, model and lots of information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70152d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = {\n",
    "  'learning_rate': 0.06795566766046571,\n",
    "  'max_depth': 74,\n",
    "  'min_child_weight': 1.1034760099449035,\n",
    "  'reg_alpha': 0.08418429054929681,\n",
    "  'reg_lambda': 0.007240669500118009,\n",
    "  'objective': 'reg:squarederror',\n",
    "  'seed': 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6642aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.xgboost.autolog()\n",
    "\n",
    "booster = xgb.train(\n",
    "  params=best_hps,\n",
    "  dtrain=train,\n",
    "  num_boost_round=1000,\n",
    "  evals=[(valid, \"validation\")],\n",
    "  early_stopping_rounds=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a41940",
   "metadata": {},
   "source": [
    "### Saving and Loading the model to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660505ec",
   "metadata": {},
   "source": [
    "#### using mlflow.log_artifact()\n",
    "\n",
    "Needs the model to be saved previously on the local system, then move it to mlflow artifacts \\\n",
    "To run the model again you need to download it from the artifacts and then load it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf80654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "mlflow.xgboost.autolog(disable=True)\n",
    "\n",
    "with mlflow.start_run():\n",
    "  mlflow.set_tag(\"developer\", \"kamal\")\n",
    "  \n",
    "  mlflow.log_param(\"train-data-path\", \"../data/green_tripdata_2021-01.parquet\")\n",
    "  mlflow.log_param(\"validation-data-path\", \"../data/green_tripdata_2021-02.parquet\")\n",
    "\n",
    "  mlflow.log_params(best_hps)\n",
    "\n",
    "  booster = xgb.train(\n",
    "    params=best_hps,\n",
    "    dtrain=train,\n",
    "    num_boost_round=10,\n",
    "    evals=[(valid, \"validation\")],\n",
    "    early_stopping_rounds=50\n",
    "  )\n",
    "\n",
    "  y_valid_predictions = booster.predict(valid)\n",
    "  rmse = root_mean_squared_error(y_true=y_val, y_pred=y_valid_predictions)\n",
    "\n",
    "  mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "  with open(\"models/booster.bin\", \"wb\") as model_file:\n",
    "    pickle.dump(booster, model_file)\n",
    "\n",
    "  mlflow.log_artifact(local_path=\"models/booster.bin\", artifact_path=\"pickle_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8e3dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/booster.bin\", \"rb\") as booster_file:\n",
    "  loaded_booster = pickle.load(booster_file)\n",
    "\n",
    "temp = loaded_booster.predict(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f5f055",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5239bc53",
   "metadata": {},
   "source": [
    "#### Using mlflow.{FrameWork}.log_model()\n",
    "\n",
    "This provides a more reliable way to load and deploy the trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b581cd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.xgboost\n",
    "\n",
    "\n",
    "mlflow.xgboost.autolog(disable=True)\n",
    "\n",
    "with mlflow.start_run(run_name=\"saving_using_mlflow.xgboost.log_model()_with_preprocessor\"):\n",
    "  mlflow.set_tag(\"developer\", \"kamal\")\n",
    "  \n",
    "  mlflow.log_param(\"train-data-path\", \"../data/green_tripdata_2021-01.parquet\")\n",
    "  mlflow.log_param(\"validation-data-path\", \"../data/green_tripdata_2021-02.parquet\")\n",
    "\n",
    "  mlflow.log_params(best_hps)\n",
    "\n",
    "  booster = xgb.train(\n",
    "    params=best_hps,\n",
    "    dtrain=train,\n",
    "    num_boost_round=10,\n",
    "    evals=[(valid, \"validation\")],\n",
    "    early_stopping_rounds=50\n",
    "  )\n",
    "\n",
    "  y_valid_predictions = booster.predict(valid)\n",
    "  rmse = root_mean_squared_error(y_true=y_val, y_pred=y_valid_predictions)\n",
    "\n",
    "  mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "  with open(\"models/preprocessor.bin\", \"wb\") as preprocessor_file:\n",
    "    pickle.dump(dv, preprocessor_file)\n",
    "\n",
    "  mlflow.log_artifact(\"models/preprocessor.bin\", \"preprocessors\")\n",
    "\n",
    "\n",
    "  # artifact_path is deprecated, use name istead\n",
    "  # Mlflow new versions separts Runs from their models\n",
    "  # when specifying the \"name\" parameter then it's the name of the trained model\n",
    "  mlflow.xgboost.log_model(booster, name=\"models_mlflow\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8869b2fe",
   "metadata": {},
   "source": [
    "### Loading Model from artifacts and make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6c68b0",
   "metadata": {},
   "source": [
    "#### Loading the model as a python function flavour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3771b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logged_model = 'runs:/ab3f2144e5b5471fa60f5ba979ae2a04/models_mlflow'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fbb30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515fe7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.predict(X_val)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43ed606",
   "metadata": {},
   "source": [
    "#### Loading the model as XGBoost object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5310e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logged_model = 'runs:/ab3f2144e5b5471fa60f5ba979ae2a04/models_mlflow'\n",
    "\n",
    "loaded_model = mlflow.xgboost.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d6b6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9f9cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.predict(valid)[:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLOps-zoomcamp-SN1OqVDr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
